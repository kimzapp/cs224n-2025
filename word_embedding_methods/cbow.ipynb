{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6070e53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x22675dab5b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc16bfda",
   "metadata": {},
   "source": [
    "Raw text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ce0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ba8339",
   "metadata": {},
   "source": [
    "Build vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c4ad6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = WordPunctTokenizer()\n",
    "tokens = tokenizer.tokenize(raw_text.lower())\n",
    "vocab = list(set(tokens))\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbba95b",
   "metadata": {},
   "source": [
    "Build context and target pari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ac14e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 random samples\n",
      "[(['we', 'are', 'to', 'study'], 'about'),\n",
      " (['are', 'about', 'study', 'the'], 'to'),\n",
      " (['about', 'to', 'the', 'idea'], 'study'),\n",
      " (['to', 'study', 'idea', 'of'], 'the'),\n",
      " (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "context_size = 2\n",
    "\n",
    "data = []\n",
    "for token in tokens[context_size:-context_size]:  # ignore boundary tokens\n",
    "    token_index = tokens.index(token)\n",
    "    context = tokens[token_index - context_size: token_index] + tokens[token_index + 1: token_index + context_size + 1]\n",
    "    target = token\n",
    "    data.append((context, target))\n",
    "\n",
    "print(\"5 random samples\")\n",
    "pprint(data[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b52aa",
   "metadata": {},
   "source": [
    "Helper function to create context vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c975f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ind2word = {i:w for i, w in enumerate(vocab)}\n",
    "word2ind = {w:i for i, w in enumerate(vocab)}\n",
    "\n",
    "def make_context_vector(context, word2ind):\n",
    "    idxs = [word2ind[w] for w in context]\n",
    "    return torch.tensor(idxs, dtype=torch.long)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d838b7da",
   "metadata": {},
   "source": [
    "CBOW:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48dbb2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim=128):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embedding_dim)\n",
    "        self.proj = nn.Linear(in_features=embedding_dim, out_features=128)\n",
    "        self.output = nn.Linear(in_features=128, out_features=vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = sum(self.embedding(inputs)).view(1, -1)\n",
    "        proj = self.proj(embeds)\n",
    "        out = self.output(proj)\n",
    "        nll_prob = F.log_softmax(out, dim=-1)\n",
    "        return nll_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39497205",
   "metadata": {},
   "source": [
    "Train model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0bfba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 10\n",
    "\n",
    "cbow = CBOW(vocab_size=vocab_size, embedding_dim=embedding_dim)\n",
    "optimizer = torch.optim.SGD(cbow.parameters(), lr=0.001)\n",
    "\n",
    "losses = []\n",
    "loss = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "317ab497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 140.92402005195618\n",
      "Epoch 2, Loss: 134.67801320552826\n",
      "Epoch 3, Loss: 128.90018022060394\n",
      "Epoch 4, Loss: 123.53096604347229\n",
      "Epoch 5, Loss: 118.5208885371685\n",
      "Epoch 6, Loss: 113.82911732792854\n",
      "Epoch 7, Loss: 109.42193755507469\n",
      "Epoch 8, Loss: 105.27136409282684\n",
      "Epoch 9, Loss: 101.353968501091\n",
      "Epoch 10, Loss: 97.64996945858002\n",
      "Epoch 11, Loss: 94.14246702194214\n",
      "Epoch 12, Loss: 90.81686639785767\n",
      "Epoch 13, Loss: 87.660389482975\n",
      "Epoch 14, Loss: 84.66169247031212\n",
      "Epoch 15, Loss: 81.81060990691185\n",
      "Epoch 16, Loss: 79.09790739417076\n",
      "Epoch 17, Loss: 76.51513168215752\n",
      "Epoch 18, Loss: 74.05449417233467\n",
      "Epoch 19, Loss: 71.70878595113754\n",
      "Epoch 20, Loss: 69.4712925851345\n",
      "Epoch 21, Loss: 67.33575594425201\n",
      "Epoch 22, Loss: 65.29632915556431\n",
      "Epoch 23, Loss: 63.347537979483604\n",
      "Epoch 24, Loss: 61.484277084469795\n",
      "Epoch 25, Loss: 59.70174977183342\n",
      "Epoch 26, Loss: 57.99547204375267\n",
      "Epoch 27, Loss: 56.361248672008514\n",
      "Epoch 28, Loss: 54.79515051841736\n",
      "Epoch 29, Loss: 53.293517887592316\n",
      "Epoch 30, Loss: 51.85291047394276\n",
      "Epoch 31, Loss: 50.47011774778366\n",
      "Epoch 32, Loss: 49.1421417593956\n",
      "Epoch 33, Loss: 47.86617824435234\n",
      "Epoch 34, Loss: 46.639601826667786\n",
      "Epoch 35, Loss: 45.45995859801769\n",
      "Epoch 36, Loss: 44.3249499052763\n",
      "Epoch 37, Loss: 43.23241928219795\n",
      "Epoch 38, Loss: 42.18035423755646\n",
      "Epoch 39, Loss: 41.1668544113636\n",
      "Epoch 40, Loss: 40.19014544785023\n",
      "Epoch 41, Loss: 39.248541817069054\n",
      "Epoch 42, Loss: 38.34046941995621\n",
      "Epoch 43, Loss: 37.46443459391594\n",
      "Epoch 44, Loss: 36.61903504282236\n",
      "Epoch 45, Loss: 35.80293157696724\n",
      "Epoch 46, Loss: 35.01486264169216\n",
      "Epoch 47, Loss: 34.25362926721573\n",
      "Epoch 48, Loss: 33.51809800416231\n",
      "Epoch 49, Loss: 32.80718260258436\n",
      "Epoch 50, Loss: 32.119852028787136\n",
      "Epoch 51, Loss: 31.4551290422678\n",
      "Epoch 52, Loss: 30.81207349151373\n",
      "Epoch 53, Loss: 30.1897951066494\n",
      "Epoch 54, Loss: 29.587441131472588\n",
      "Epoch 55, Loss: 29.00419821590185\n",
      "Epoch 56, Loss: 28.43929134309292\n",
      "Epoch 57, Loss: 27.891975328326225\n",
      "Epoch 58, Loss: 27.361536718904972\n",
      "Epoch 59, Loss: 26.847304493188858\n",
      "Epoch 60, Loss: 26.34862933307886\n",
      "Epoch 61, Loss: 25.86488738656044\n",
      "Epoch 62, Loss: 25.395489491522312\n",
      "Epoch 63, Loss: 24.93986824899912\n",
      "Epoch 64, Loss: 24.49748718738556\n",
      "Epoch 65, Loss: 24.067829132080078\n",
      "Epoch 66, Loss: 23.65039836615324\n",
      "Epoch 67, Loss: 23.244725115597248\n",
      "Epoch 68, Loss: 22.850360050797462\n",
      "Epoch 69, Loss: 22.466876983642578\n",
      "Epoch 70, Loss: 22.093857057392597\n",
      "Epoch 71, Loss: 21.73091746866703\n",
      "Epoch 72, Loss: 21.377676375210285\n",
      "Epoch 73, Loss: 21.033779628574848\n",
      "Epoch 74, Loss: 20.698885560035706\n",
      "Epoch 75, Loss: 20.37266642600298\n",
      "Epoch 76, Loss: 20.05481082201004\n",
      "Epoch 77, Loss: 19.7450200766325\n",
      "Epoch 78, Loss: 19.443011302500963\n",
      "Epoch 79, Loss: 19.148509483784437\n",
      "Epoch 80, Loss: 18.861254785209894\n",
      "Epoch 81, Loss: 18.580998960882425\n",
      "Epoch 82, Loss: 18.30750735476613\n",
      "Epoch 83, Loss: 18.0405445471406\n",
      "Epoch 84, Loss: 17.779898263514042\n",
      "Epoch 85, Loss: 17.525357522070408\n",
      "Epoch 86, Loss: 17.276722386479378\n",
      "Epoch 87, Loss: 17.0337972715497\n",
      "Epoch 88, Loss: 16.796403009444475\n",
      "Epoch 89, Loss: 16.564364191144705\n",
      "Epoch 90, Loss: 16.33750820532441\n",
      "Epoch 91, Loss: 16.11567321047187\n",
      "Epoch 92, Loss: 15.898707572370768\n",
      "Epoch 93, Loss: 15.686459299176931\n",
      "Epoch 94, Loss: 15.478782501071692\n",
      "Epoch 95, Loss: 15.275541197508574\n",
      "Epoch 96, Loss: 15.076605297625065\n",
      "Epoch 97, Loss: 14.881842788308859\n",
      "Epoch 98, Loss: 14.691133718937635\n",
      "Epoch 99, Loss: 14.50436431914568\n",
      "Epoch 100, Loss: 14.321410570293665\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "cbow.to(device)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0\n",
    "    for context, target in data:\n",
    "        context_vector = make_context_vector(context, word2ind).to(device)\n",
    "        target_vector = torch.tensor([word2ind[target]], dtype=torch.long).to(device)\n",
    "\n",
    "        nll_prob = cbow(context_vector)\n",
    "\n",
    "        cbow.zero_grad()\n",
    "\n",
    "        l = loss(nll_prob, target_vector)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += l.item()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")\n",
    "    losses.append(total_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd049c",
   "metadata": {},
   "source": [
    "Predict:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fddc56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw text: We are about to study the idea of a computational process.\n",
      "Computational processes are abstract beings that inhabit computers.\n",
      "As they evolve, processes manipulate other abstract things called data.\n",
      "The evolution of a process is directed by a pattern of rules\n",
      "called a program. People create programs to direct processes. In effect,\n",
      "we conjure the spirits of the computer with our spells.\n",
      "Test Context: ['we', 'are', 'to', 'study']\n",
      "\n",
      "Prediction: about\n"
     ]
    }
   ],
   "source": [
    "context = ['we','are','to', 'study']\n",
    "context_vector = make_context_vector(context, word2ind).to(device)\n",
    "a = cbow(context_vector).detach().cpu().squeeze()\n",
    "print(f'Raw text: {raw_text}')\n",
    "print(f'Test Context: {context}')\n",
    "max_idx = torch.argmax(a, axis=-1).item()\n",
    "print(f'\\nPrediction: {ind2word[max_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7720634",
   "metadata": {},
   "source": [
    "Visualize embedding results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc94f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a8fe080",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m embedder \u001b[38;5;241m=\u001b[39m cbow\u001b[38;5;241m.\u001b[39membedding\n\u001b[0;32m      2\u001b[0m sample_words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomputer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprogram\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeople\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m embedded_words \u001b[38;5;241m=\u001b[39m {word: embedder\u001b[38;5;241m.\u001b[39mweight[word2ind[word]]\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sample_words}\n",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m embedder \u001b[38;5;241m=\u001b[39m cbow\u001b[38;5;241m.\u001b[39membedding\n\u001b[0;32m      2\u001b[0m sample_words \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprocess\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomputer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprogram\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpeople\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwe\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 3\u001b[0m embedded_words \u001b[38;5;241m=\u001b[39m {word: \u001b[43membedder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword2ind\u001b[49m\u001b[43m[\u001b[49m\u001b[43mword\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m sample_words}\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "embedder = cbow.embedding\n",
    "sample_words = ['process', 'computer', 'data', 'program', 'people', 'we']\n",
    "embedded_words = {word: embedder.weight[word2ind[word]].detach().cpu().numpy() for word in sample_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bdc89487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'process': tensor([ 1.0636, -0.6141,  0.4515,  1.0341, -1.0069, -2.1825,  0.3395, -0.4446,\n",
       "          0.1524,  0.0487]),\n",
       " 'computer': tensor([-0.8820,  0.0048, -1.2720, -1.0824,  0.7433,  0.3217,  0.3317, -1.5989,\n",
       "          0.2196,  0.2818]),\n",
       " 'data': tensor([-1.0211,  0.3959,  0.9917,  0.9879, -1.1777, -0.5731, -1.4529, -0.3053,\n",
       "         -0.2835,  0.1194]),\n",
       " 'program': tensor([ 0.8851, -0.4767, -0.1831, -0.1010,  0.1492,  2.4369,  1.3275, -0.2773,\n",
       "          0.7176, -0.1568]),\n",
       " 'people': tensor([-0.3989, -0.0460, -0.0509, -0.9866,  0.0163, -1.0345, -0.0870, -0.6354,\n",
       "          0.8794,  0.1424]),\n",
       " 'we': tensor([-0.6532, -1.6436, -0.0586,  0.6232,  0.2843, -0.6979,  1.6385,  0.3350,\n",
       "          0.0041,  0.3089])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs224n",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
